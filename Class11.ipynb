{
 "metadata": {
  "name": "",
  "signature": "sha256:4b55ee120abe74e146d6c6d0ebaa5697e2aef14709468fb3a39d48b938976ff9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data, the Humanist's New Best Friend"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this class you are expected to learn:\n",
      "* NLTK\n",
      "* Tokenization\n",
      "* Concordance\n",
      "* Word and phrase frequencies\n",
      "* Dispersion plots\n",
      "* TextBlob"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div align=\"center\">\n",
      "<img src=\"files/images/nlp.jpg\" width=\"350\">\n",
      "*It really is awesome!*\n",
      "</div>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Natural Language Processing (NLP)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Extracted from [Tooling up for Digital Humanities: The Text Deluge](http://toolingup.stanford.edu/?page_id=349) (highly recommended reading!):\n",
      "\n",
      "> According to [one estimate](http://www.economist.com/node/15579717?story_id=15579717), human beings created some 150 exabytes (billion gigabytes) of data in 2005 alone. This year, we will create approximately 1,200 exabytes. The Library of Congress [announced](http://www.guardian.co.uk/world/richard-adams-blog/2010/apr/14/twitter-library-of-congress) its decision archive Twitter, which includes the addition of some 50 million tweets per day. A search in Google Books for the phrase \u201cslave trade\u201d in July 2010, for example, returned the following: \u201cAbout 1,600,000 results (0.21 seconds).\u201d Scholars once accustomed to studying a handful of letters or a couple hundred diary entries are now faced with massive amounts of data that cannot possibly be analyzed in traditional ways.\n",
      ">\n",
      "> The trend towards an increasing deluge of information raises the question posed by Gregory Crane in 2006: \u201c**What do you do with a million books?**\u201d \u201cMy answer to that question\u201d wrote Tanya Clement and others in a 2008 article, \u201cis that **whatever you do, you don't read them, because you can\u2019t**.\u201d\n",
      "\n",
      "And that's the key for text analysis today: to not read, which is still kind of ironic. But then, if we can't read one million books, or blogs, or a trillion of tweets, of hundred thousand of margin notes, how are we supposed to analyze that? The answer is Natural Language Processing, or **NLP**.\n",
      "\n",
      "There is a bunch of things that NLP can do for us, I'll list some of them:\n",
      "\n",
      "- [Automatic summarization](https://en.wikipedia.org/wiki/Automatic_summarization).\n",
      "- [Coreference resolution](https://en.wikipedia.org/wiki/Coreference).\n",
      "- [Discourse analysis](https://en.wikipedia.org/wiki/Discourse_analysis).\n",
      "- [Machine translation](https://en.wikipedia.org/wiki/Machine_translation).\n",
      "- [Morphological segmentation](https://en.wikipedia.org/wiki/Morphology_).\n",
      "- [Named entity recognition](https://en.wikipedia.org/wiki/Named_entity_recognition).\n",
      "- [Natural language generation](https://en.wikipedia.org/wiki/Natural_language_generation).\n",
      "- [Natural language understanding](https://en.wikipedia.org/wiki/Natural_language_understanding).\n",
      "- [Optical character recognition](https://en.wikipedia.org/wiki/Optical_character_recognition).\n",
      "- [Part-of-speech tagging](https://en.wikipedia.org/wiki/Part).\n",
      "- [Parsing](https://en.wikipedia.org/wiki/Parsing).\n",
      "- [Question answering](https://en.wikipedia.org/wiki/Question_answering).\n",
      "- [Relationship extraction](https://en.wikipedia.org/wiki/Relationship_extraction).\n",
      "- [Sentence breaking](https://en.wikipedia.org/wiki/Sentence_breaking).\n",
      "- [sentence boundary disambiguation](https://en.wikipedia.org/wiki/Sentence_boundary_disambiguation).\n",
      "- [Sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis).\n",
      "- [Speech recognition](https://en.wikipedia.org/wiki/Speech_recognition).\n",
      "- [Speech segmentation](https://en.wikipedia.org/wiki/Speech_segmentation).\n",
      "- [Topic segmentation](https://en.wikipedia.org/wiki/Topic_segmentation).\n",
      "- [Word segmentation](https://en.wikipedia.org/wiki/Word_segmentation).\n",
      "- [Word sense disambiguation](https://en.wikipedia.org/wiki/Word_sense_disambiguation).\n",
      "- [Information retrieval](https://en.wikipedia.org/wiki/Information_retrieval).\n",
      "- [Information extraction](https://en.wikipedia.org/wiki/Information_extraction).\n",
      "- [Speech processing](https://en.wikipedia.org//wiki/Speech_processing).\n",
      "\n",
      "For most of them there is a package in Python, and most of the time that package is the [Natural Language Toolkit](http://www.nltk.org/), usually abbreviated as NLTK."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "NLTK"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Natural Language Toolkit is a huge package tha covers almost every need you might have about text processing. It was designed with four primary goals in mind:\n",
      "- **Simplicity**: To provide an intuitive framework along with substantial building blocks, giving users a practical knowledge of NLP without getting bogged down in the tedious house-keeping usually associated with processing annotated language data.\n",
      "- **Consistency**: To provide a uniform framework with consistent interfaces and data structures, and easily-guessable method names.\n",
      "- **Extensibility**: To provide a structure into which new software modules can be easily accommodated, including alternative implementations and competing approaches to the same task.\n",
      "- **Modularity**: To provide components that can be used independently without needing to understand the rest of the toolkit.\n",
      "\n",
      "The list of features is overwhelming. Unfortunately, we'll see a fraction of those.\n",
      "<table border=\"1\" class=\"docutils\" id=\"tab-modules\">\n",
      "<colgroup>\n",
      "<col width=\"24%\">\n",
      "<col width=\"24%\">\n",
      "<col width=\"53%\">\n",
      "</colgroup>\n",
      "<thead valign=\"bottom\">\n",
      "<tr><th class=\"head\">Language processing task</th>\n",
      "<th class=\"head\">NLTK modules</th>\n",
      "<th class=\"head\">Functionality</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody valign=\"top\">\n",
      "<tr><td>Accessing corpora</td>\n",
      "<td>`nltk.corpus`</td>\n",
      "<td>standardized interfaces to corpora and lexicons</td>\n",
      "</tr>\n",
      "<tr><td>String processing</td>\n",
      "<td>`nltk.tokenize`, `nltk.stem`</td>\n",
      "<td>tokenizers, sentence tokenizers, stemmers</td>\n",
      "</tr>\n",
      "<tr><td>Collocation discovery</td>\n",
      "<td>`nltk.collocations`</td>\n",
      "<td>t-test, chi-squared, point-wise mutual information</td>\n",
      "</tr>\n",
      "<tr><td>Part-of-speech tagging</td>\n",
      "<td>`nltk.tag`</td>\n",
      "<td>n-gram, backoff, Brill, HMM, TnT</td>\n",
      "</tr>\n",
      "<tr><td>Classification</td>\n",
      "<td>`nltk.classify`, `nltk.cluster`</td>\n",
      "<td>decision tree, maximum entropy, naive Bayes, EM, k-means</td>\n",
      "</tr>\n",
      "<tr><td>Chunking</td>\n",
      "<td>`nltk.chunk`</td>\n",
      "<td>regular expression, n-gram, named-entity</td>\n",
      "</tr>\n",
      "<tr><td>Parsing</td>\n",
      "<td>`nltk.parse`</td>\n",
      "<td>chart, feature-based, unification, probabilistic, dependency</td>\n",
      "</tr>\n",
      "<tr><td>Semantic interpretation</td>\n",
      "<td>`nltk.sem`, `nltk.inference`</td>\n",
      "<td>lambda calculus, first-order logic, model checking</td>\n",
      "</tr>\n",
      "<tr><td>Evaluation metrics</td>\n",
      "<td>`nltk.metrics`</td>\n",
      "<td>precision, recall, agreement coefficients</td>\n",
      "</tr>\n",
      "<tr><td>Probability and estimation</td>\n",
      "<td>`nltk.probability`</td>\n",
      "<td>frequency distributions, smoothed probability distributions</td>\n",
      "</tr>\n",
      "<tr><td>Applications</td>\n",
      "<td>`nltk.app`, `nltk.chat`</td>\n",
      "<td>graphical concordancer, parsers, WordNet browser, chatbots</td>\n",
      "</tr>\n",
      "<tr><td>Linguistic fieldwork</td>\n",
      "<td>`nltk.toolbox`</td>\n",
      "<td>manipulate data in SIL Toolbox format</td>\n",
      "</tr>\n",
      "</tbody>\n",
      "\n",
      "\n",
      "</table>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If this is the first time you use NLTK (and I'm pretty sure it is), you need to download some files that NLTK needs, like example books, corpora, information for the tagger, dictionaries, etc. NLTK brings its own downloader, all you have to do is importing the module and invoking `download()`. The downloader then will ask you what do you want to do, so you type `d` for downloading, and then `all` to download everything, everything! It may take some time, but you'll do this only once."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk \n",
      "nltk.download()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NLTK Downloader\n",
        "---------------------------------------------------------------------------\n",
        "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
        "---------------------------------------------------------------------------\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Downloader> d\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Download which package (l=list; x=cancel)?\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Identifier> l\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Packages:\n",
        "  [-] book_grammars....... Grammars from NLTK Book"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [-] brown............... Brown Corpus\n",
        "  [ ] framenet_v15........ FrameNet 1.5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [-] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [-] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
        "  [-] punkt............... Punkt Tokenizer Models"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [-] sample_grammars..... Sample Grammars"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [-] tagsets............. Help on Tagsets"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [-] udhr2............... Universal Declaration of Human Rights Corpus\n",
        "                           (Unicode Version)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Collections:\n",
        "  [-] all-corpora......... All the corpora\n",
        "  [-] all................. All packages\n",
        "  [-] book................ Everything used in the NLTK Book\n",
        "\n",
        "([*] marks installed packages; [-] marks out-of-date or corrupt packages)\n",
        "\n",
        "Download which package (l=list; x=cancel)?\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Identifier> book_grammars all\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    Downloading package book_grammars to /home/me/nltk_data...\n",
        "      Unzipping grammars/book_grammars.zip."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    Downloading collection 'all'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       | \n",
        "       | Downloading package abc to /home/me/nltk_data...\n",
        "       |   Package abc is already up-to-date!\n",
        "       | Downloading package alpino to /home/me/nltk_data...\n",
        "       |   Package alpino is already up-to-date!\n",
        "       | Downloading package biocreative_ppi to\n",
        "       |     /home/me/nltk_data...\n",
        "       |   Package biocreative_ppi is already up-to-date!\n",
        "       | Downloading package brown to /home/me/nltk_data...\n",
        "       |   Unzipping corpora/brown.zip."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       | Downloading package brown_tei to /home/me/nltk_data..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       |   Package brown_tei is already up-to-date!\n",
        "       | Downloading package cess_cat to /home/me/nltk_data...\n",
        "       |   Package cess_cat is already up-to-date!\n",
        "       | Downloading package cess_esp to /home/me/nltk_data...\n",
        "       |   Package cess_esp is already up-to-date!\n",
        "       | Downloading package chat80 to /home/me/nltk_data...\n",
        "       |   Package chat80 is already up-to-date!\n",
        "       | Downloading package city_database to\n",
        "       |     /home/me/nltk_data...\n",
        "       |   Package city_database is already up-to-date!\n",
        "       | Downloading package cmudict to /home/me/nltk_data...\n",
        "       |   Package cmudict is already up-to-date!\n",
        "       | Downloading package comtrans to /home/me/nltk_data...\n",
        "       |   Package comtrans is already up-to-date!\n",
        "       | Downloading package conll2000 to /home/me/nltk_data...\n",
        "       |   Package conll2000 is already up-to-date!\n",
        "       | Downloading package conll2002 to /home/me/nltk_data...\n",
        "       |   Package conll2002 is already up-to-date!\n",
        "       | Downloading package conll2007 to /home/me/nltk_data...\n",
        "       |   Package conll2007 is already up-to-date!\n",
        "       | Downloading package dependency_treebank to\n",
        "       |     /home/me/nltk_data...\n",
        "       |   Package dependency_treebank is already up-to-date!\n",
        "       | Downloading package europarl_raw to /home/me/nltk_data...\n",
        "       |   Package europarl_raw is already up-to-date!\n",
        "       | Downloading package floresta to /home/me/nltk_data...\n",
        "       |   Package floresta is already up-to-date!\n",
        "       | Downloading package framenet_v15 to /home/me/nltk_data...\n",
        "       |   Unzipping corpora/framenet_v15.zip."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       | Downloading package gazetteers to /home/me/nltk_data..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       |   Package gazetteers is already up-to-date!\n",
        "       | Downloading package genesis to /home/me/nltk_data...\n",
        "       |   Package genesis is already up-to-date!\n",
        "       | Downloading package gutenberg to /home/me/nltk_data...\n",
        "       |   Package gutenberg is already up-to-date!\n",
        "       | Downloading package ieer to /home/me/nltk_data...\n",
        "       |   Package ieer is already up-to-date!\n",
        "       | Downloading package inaugural to /home/me/nltk_data...\n",
        "       |   Package inaugural is already up-to-date!\n",
        "       | Downloading package indian to /home/me/nltk_data...\n",
        "       |   Package indian is already up-to-date!\n",
        "       | Downloading package jeita to /home/me/nltk_data...\n",
        "       |   Package jeita is already up-to-date!\n",
        "       | Downloading package kimmo to /home/me/nltk_data...\n",
        "       |   Package kimmo is already up-to-date!\n",
        "       | Downloading package knbc to /home/me/nltk_data...\n",
        "       |   Package knbc is already up-to-date!\n",
        "       | Downloading package langid to /home/me/nltk_data...\n",
        "       |   Package langid is already up-to-date!\n",
        "       | Downloading package lin_thesaurus to\n",
        "       |     /home/me/nltk_data...\n",
        "       |   Package lin_thesaurus is already up-to-date!\n",
        "       | Downloading package mac_morpho to /home/me/nltk_data...\n",
        "       |   Package mac_morpho is already up-to-date!\n",
        "       | Downloading package machado to /home/me/nltk_data...\n",
        "       |   Package machado is already up-to-date!\n",
        "       | Downloading package movie_reviews to\n",
        "       |     /home/me/nltk_data...\n",
        "       |   Package movie_reviews is already up-to-date!\n",
        "       | Downloading package names to /home/me/nltk_data...\n",
        "       |   Package names is already up-to-date!\n",
        "       | Downloading package nombank.1.0 to /home/me/nltk_data...\n",
        "       |   Package nombank.1.0 is already up-to-date!\n",
        "       | Downloading package nps_chat to /home/me/nltk_data...\n",
        "       |   Package nps_chat is already up-to-date!\n",
        "       | Downloading package paradigms to /home/me/nltk_data...\n",
        "       |   Package paradigms is already up-to-date!\n",
        "       | Downloading package pil to /home/me/nltk_data...\n",
        "       |   Package pil is already up-to-date!\n",
        "       | Downloading package pl196x to /home/me/nltk_data...\n",
        "       |   Package pl196x is already up-to-date!\n",
        "       | Downloading package ppattach to /home/me/nltk_data...\n",
        "       |   Package ppattach is already up-to-date!\n",
        "       | Downloading package problem_reports to\n",
        "       |     /home/me/nltk_data...\n",
        "       |   Package problem_reports is already up-to-date!\n",
        "       | Downloading package propbank to /home/me/nltk_data...\n",
        "       |   Package propbank is already up-to-date!\n",
        "       | Downloading package ptb to /home/me/nltk_data...\n",
        "       |   Package ptb is already up-to-date!\n",
        "       | Downloading package oanc_masc to /home/me/nltk_data...\n",
        "       |   Package oanc_masc is already up-to-date!\n",
        "       | Downloading package qc to /home/me/nltk_data...\n",
        "       |   Package qc is already up-to-date!\n",
        "       | Downloading package reuters to /home/me/nltk_data...\n",
        "       |   Package reuters is already up-to-date!\n",
        "       | Downloading package rte to /home/me/nltk_data...\n",
        "       |   Package rte is already up-to-date!\n",
        "       | Downloading package semcor to /home/me/nltk_data...\n",
        "       |   Package semcor is already up-to-date!\n",
        "       | Downloading package senseval to /home/me/nltk_data...\n",
        "       |   Package senseval is already up-to-date!\n",
        "       | Downloading package shakespeare to /home/me/nltk_data...\n",
        "       |   Package shakespeare is already up-to-date!\n",
        "       | Downloading package sinica_treebank to\n",
        "       |     /home/me/nltk_data...\n",
        "       |   Package sinica_treebank is already up-to-date!\n",
        "       | Downloading package smultron to /home/me/nltk_data...\n",
        "       |   Package smultron is already up-to-date!\n",
        "       | Downloading package state_union to /home/me/nltk_data...\n",
        "       |   Package state_union is already up-to-date!\n",
        "       | Downloading package stopwords to /home/me/nltk_data...\n",
        "       |   Package stopwords is already up-to-date!\n",
        "       | Downloading package swadesh to /home/me/nltk_data...\n",
        "       |   Package swadesh is already up-to-date!\n",
        "       | Downloading package switchboard to /home/me/nltk_data...\n",
        "       |   Package switchboard is already up-to-date!\n",
        "       | Downloading package timit to /home/me/nltk_data...\n",
        "       |   Package timit is already up-to-date!\n",
        "       | Downloading package toolbox to /home/me/nltk_data...\n",
        "       |   Package toolbox is already up-to-date!\n",
        "       | Downloading package treebank to /home/me/nltk_data...\n",
        "       |   Package treebank is already up-to-date!\n",
        "       | Downloading package udhr to /home/me/nltk_data...\n",
        "       |   Package udhr is already up-to-date!\n",
        "       | Downloading package udhr2 to /home/me/nltk_data...\n",
        "       |   Unzipping corpora/udhr2.zip."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       | Downloading package unicode_samples to\n",
        "       |     /home/me/nltk_data..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       |   Package unicode_samples is already up-to-date!\n",
        "       | Downloading package verbnet to /home/me/nltk_data...\n",
        "       |   Package verbnet is already up-to-date!\n",
        "       | Downloading package webtext to /home/me/nltk_data...\n",
        "       |   Package webtext is already up-to-date!\n",
        "       | Downloading package wordnet to /home/me/nltk_data...\n",
        "       |   Package wordnet is already up-to-date!\n",
        "       | Downloading package wordnet_ic to /home/me/nltk_data...\n",
        "       |   Package wordnet_ic is already up-to-date!\n",
        "       | Downloading package words to /home/me/nltk_data...\n",
        "       |   Package words is already up-to-date!\n",
        "       | Downloading package ycoe to /home/me/nltk_data...\n",
        "       |   Package ycoe is already up-to-date!\n",
        "       | Downloading package rslp to /home/me/nltk_data...\n",
        "       |   Package rslp is already up-to-date!\n",
        "       | Downloading package hmm_treebank_pos_tagger to\n",
        "       |     /home/me/nltk_data...\n",
        "       |   Package hmm_treebank_pos_tagger is already up-to-date!\n",
        "       | Downloading package maxent_treebank_pos_tagger to\n",
        "       |     /home/me/nltk_data...\n",
        "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       | Downloading package universal_tagset to\n",
        "       |     /home/me/nltk_data..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       |   Unzipping taggers/universal_tagset.zip."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       | Downloading package maxent_ne_chunker to\n",
        "       |     /home/me/nltk_data..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       |   Unzipping chunkers/maxent_ne_chunker.zip."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       | Downloading package punkt to /home/me/nltk_data..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       |   Unzipping tokenizers/punkt.zip."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       | Downloading package book_grammars to\n",
        "       |     /home/me/nltk_data..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       |   Package book_grammars is already up-to-date!\n",
        "       | Downloading package sample_grammars to\n",
        "       |     /home/me/nltk_data...\n",
        "       |   Unzipping grammars/sample_grammars.zip."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       | Downloading package spanish_grammars to\n",
        "       |     /home/me/nltk_data..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       |   Package spanish_grammars is already up-to-date!\n",
        "       | Downloading package basque_grammars to\n",
        "       |     /home/me/nltk_data...\n",
        "       |   Package basque_grammars is already up-to-date!\n",
        "       | Downloading package large_grammars to\n",
        "       |     /home/me/nltk_data...\n",
        "       |   Package large_grammars is already up-to-date!\n",
        "       | Downloading package tagsets to /home/me/nltk_data...\n",
        "       | "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     Done downloading collection all\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
        "---------------------------------------------------------------------------\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Downloader> q\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After downloading everythin, we've gained acccess to a corpus of books to play with. One of them is *Moby Dick* by Herman Melville, under `nltk.book.text1`; other is *Sense and Sensibility* by Jane Austen, under `nltk.books.text2`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.book import text1 as moby_dick\n",
      "moby_dick"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "<Text: Moby Dick by Herman Melville 1851>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.book import text2 as sense_sensibility\n",
      "sense_sensibility"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<Text: Sense and Sensibility by Jane Austen 1811>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Searching text"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These included books are actually instances of `Text`, which is a class defined by NLTK that behaves like a very rich collection of strings. However, regular operations like checking if a word is in a text, or slicing part of the text, is done the same way that in strings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(sense_sensibility)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "nltk.text.Text"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"love\" in sense_sensibility"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sense_sensibility.index(\"love\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "1447"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sense_sensibility[1447:1452]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "['love', 'for', 'all', 'her', 'three']"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that slicing a `Text` gives us words and punctuation symbols, or **tokens**, instead of characters."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are many ways to examine the **context** of a text apart from simply reading it. A **concordance** view shows us every occurrence of a given word, together with some context. Here we look up the word \"love\" in our two books; unsurprisingly, there is way more matches in Sense and Sensibility than it Moby Dick."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sense_sensibility.concordance(\"love\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Displaying 25 of 77 matches:\n",
        "priety of going , and her own tender love for all her three children determine\n",
        "es .\" \" I believe you are right , my love ; it will be better that there shoul\n",
        " . It implies everything amiable . I love him already .\" \" I think you will li\n",
        "sentiment of approbation inferior to love .\" \" You may esteem him .\" \" I have \n",
        "n what it was to separate esteem and love .\" Mrs . Dashwood now took pains to \n",
        "oner did she perceive any symptom of love in his behaviour to Elinor , than sh\n",
        " how shall we do without her ?\" \" My love , it will be scarcely a separation .\n",
        "ise . Edward is very amiable , and I love him tenderly . But yet -- he is not \n",
        "ll never see a man whom I can really love . I require so much ! He must have a\n",
        "ry possible charm .\" \" Remember , my love , that you are not seventeen . It is\n",
        "f I do not now . When you tell me to love him as a brother , I shall no more s\n",
        "hat Colonel Brandon was very much in love with Marianne Dashwood . She rather \n",
        "e were ever animated enough to be in love , must have long outlived every sens\n",
        "hirty - five anything near enough to love , to make him a desirable companion \n",
        "roach would have been spared .\" \" My love ,\" said her mother , \" you must not \n",
        "pect that the misery of disappointed love had already been known to him . This\n",
        " most melancholy order of disastrous love . CHAPTER 12 As Elinor and Marianne \n",
        "hen she considered what Marianne ' s love for him was , a quarrel seemed almos\n",
        "ctory way ;-- but you , Elinor , who love to doubt where you can -- it will no\n",
        " man whom we have all such reason to love , and no reason in the world to thin\n",
        "ded as he must be of your sister ' s love , should leave her , and leave her p\n",
        "cannot think that . He must and does love her I am sure .\" \" But with a strang\n",
        " I believe not ,\" cried Elinor . \" I love Willoughby , sincerely love him ; an\n",
        "or . \" I love Willoughby , sincerely love him ; and suspicion of his integrity\n",
        "deed a man could not very well be in love with either of her daughters , witho\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "moby_dick.concordance(\"love\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Displaying 24 of 24 matches:\n",
        " to bespeak a monument for her first love , who had been killed by a whale in \n",
        "erlasting itch for things remote . I love to sail forbidden seas , and land on\n",
        "astic our stiff prejudices grow when love once comes to bend them . For now I \n",
        "ng . Now , it was plainly a labor of love for Captain Sleet to describe , as h\n",
        "he whole , I greatly admire and even love the brave , the honest , and learned\n",
        "to - night with hearts as light , To love , as gay and fleeting As bubbles tha\n",
        "he fleece of celestial innocence and love ; and hence , by bringing together t\n",
        "s this visible world seems formed in love , the invisible spheres were formed \n",
        "tism in them , still , while for the love of it they give chase to Moby Dick ,\n",
        "own hearty good - will and brotherly love about it at all . As touching Slave \n",
        "stubborn , as malicious . He did not love Steelkilt , and Steelkilt knew it . \n",
        " of sea - usages and the instinctive love of neatness in seamen ; some of whom\n",
        "g to let that rascal beat ye ? Do ye love brandy ? A hogshead of brandy , then\n",
        "h a sog ! such a sogger ! Don ' t ye love sperm ? There goes three thousand do\n",
        "atever they may reveal of the divine love in the Son , the soft , curled , her\n",
        " come to deadly battle , and all for love . They fence with their long lower j\n",
        "de overtakes the sated Turk ; then a love of ease and virtue supplants the lov\n",
        "ove of ease and virtue supplants the love for maidens ; our Ottoman enters upo\n",
        "go , the Virgin ! that ' s our first love ; we marry and think to be happy for\n",
        "Tranquo , being gifted with a devout love for all matters of barbaric vertu , \n",
        "ght worship is defiance . To neither love nor reverence wilt thou be kind ; an\n",
        " is woe . Come in thy lowest form of love , and I will kneel and kiss thee ; b\n",
        "es , yet full of the sweet things of love and gratitude . Come ! I feel proude\n",
        "dihood of a Nantucketer ' s paternal love , had thus early sought to initiate \n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div style=\"font-size: 1em; margin: 1em 0 1em 0; border: 1px solid #86989B; background-color: #f7f7f7; padding: 0;\">\n",
      "<p style=\"margin: 0; padding: 0.1em 0 0.1em 0.5em; color: white; border-bottom: 1px solid #86989B; font-weight: bold; background-color: #AFC1C4;\">\n",
      "Activity\n",
      "</p>\n",
      "<p style=\"margin: 0.5em 1em 0.5em 1em; padding: 0;\">\n",
      "What would you expect when searching for word \"monstrous\" in these two books? Sure? Let's see it!\n",
      "</p>\n",
      "</div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "moby_dick.concordance(\"monstrous\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sense_sensibility.concordance(\"monstrous\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div style=\"font-size: 1em; margin: 1em 0 1em 0; border: 1px solid #86989B; background-color: #f7f7f7; padding: 0;\">\n",
      "<p style=\"margin: 0; padding: 0.1em 0 0.1em 0.5em; color: white; border-bottom: 1px solid #86989B; font-weight: bold; background-color: #AFC1C4;\">\n",
      "Activity\n",
      "</p>\n",
      "<p style=\"margin: 0.5em 1em 0.5em 1em; padding: 0;\">\n",
      "The *NPS Chat Corpus*, under `nltk.book.text5`, is uncensored. Try search for words like \"lol\".\n",
      "</p>\n",
      "</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A concordance permits us to see words in context. For example, we saw that \"love\" occurred in contexts such as the \"of\" and \"and\". What other words appear in a similar range of contexts? We can find out by using the `similar()` function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "moby_dick.similar(\"love\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Building word-context index...\n",
        "man sea it ship ahab air blubber boats bone by captain chase death\n",
        "fear gush hand head him hope land"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sense_sensibility.similar(\"love\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Building word-context index...\n",
        "affection heart mother see sister time town dear elinor it life\n",
        "marianne me word bed do family head her him"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Observe that we get different results for different texts. Austen uses this word quite differently from Melville; for her, \"love\" has connotations related to the family, and usually goes along with \"him\". The function `common_contexts()` allows us to examine just the contexts that are shared by two or more words, such as \"love\" with \"him\" or \"her\", by passing them as a list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sense_sensibility.common_contexts([\"love\", \"him\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "in_by of_in to_and to_but to_you\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sense_sensibility.common_contexts([\"love\", \"her\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "in_more to_and to_but to_to to_you\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This means that in the text, the words \"love\" and \"him\" appear toghether with those specigic surroundings:\n",
      "\n",
      "- *in* love her *more*\n",
      "- *to* love her *and*\n",
      "- *to* love her *but*\n",
      "- *to* love her *to*\n",
      "- *to* love her *you*\n",
      "\n",
      "Notice that punctuation is ignored by this and others functions."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Dispersion plots"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a **dispersion plot**. Each stripe represents an instance of a word, and each row represents the entire text."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Due to an issue in NLTK, we need to use the IPython magic %pylab, nothing serious\n",
      "%pylab inline\n",
      "pylab.rcParams['figure.figsize'] = (12.0, 6.0)\n",
      "from nltk.draw.dispersion import dispersion_plot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dispersion_plot(moby_dick, [\"monstrous\", \"love\", \"sail\", \"death\", \"dead\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/versae/.venvs/data/lib/python3.3/site-packages/matplotlib/backends/backend_agg.py:517: DeprecationWarning: npy_PyFile_Dup is deprecated, use npy_PyFile_Dup2\n",
        "  filename_or_obj, self.figure.dpi)\n",
        "/home/versae/.venvs/data/lib/python3.3/site-packages/matplotlib/backends/backend_agg.py:517: DeprecationWarning: npy_PyFile_Dup is deprecated, use npy_PyFile_Dup2\n",
        "  filename_or_obj, self.figure.dpi)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAvUAAAGJCAYAAAAKSsyqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAM9/8ArK+5Wi40yIIAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fdf66aa72d0>"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div style=\"font-size: 1em; margin: 1em 0 1em 0; border: 1px solid #86989B; background-color: #f7f7f7; padding: 0;\">\n",
      "<p style=\"margin: 0; padding: 0.1em 0 0.1em 0.5em; color: white; border-bottom: 1px solid #86989B; font-weight: bold; background-color: #AFC1C4;\">\n",
      "Activity\n",
      "</p>\n",
      "<p style=\"margin: 0.5em 1em 0.5em 1em; padding: 0;\">\n",
      "Get dispersion plots for words of your choice from *Sense and Sensibility*.\n",
      "</p>\n",
      "</div>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Counting words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}